# ---------------------------------------------------------------
# 0. -------------------  Master Notes  -------------------------
# ---------------------------------------------------------------
# 1. The formatting of this document came from ChatGPT. I find it very easy
#    to read as it clearly labels each section, so I kept the formattting.
# 2. Codes generated by ChatGPT or copied from outside sources are highlighted using """""" for easy reference.
"""Copied from mediawiki: https://github.com/barrust/mediawiki"""
from mediawiki import MediaWiki
WIKI = MediaWiki()

# ---------------------------------------------------------------
# 1. ------------  Titles of Wikipedia Pages  -------------------
# ---------------------------------------------------------------
SCHOOLS = [
    "Babson College",
    "Harvard University",
    "Yale University",
    "Columbia University",
    "Cornell University",
    "Princeton University",
    "Massachusetts Institute of Technology",
    "Brown University",
    "Dartmouth College",
    "University of Pennsylvania",
    "Stanford University",
    "University of Chicago",
]

REFERENCE_PAGES = [
    "Entrepreneurship",
    "U.S. News & World Report",
]

ALL_TITLES = SCHOOLS + REFERENCE_PAGES

# ---------------------------------------------------------------
# 2. ----------------  Processing Texts  ------------------------
# ---------------------------------------------------------------
""" The list punctuations is generated by ChatGPT """
PUNCT_CHARS = "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"

PUNCT_TABLE = {}
for ch in PUNCT_CHARS:
    PUNCT_TABLE[ord(ch)] = None

""" The list of stop words is generated by ChatGPT """
STOP_WORDS = {
    "the",
    "and",
    "of",
    "to",
    "in",
    "a",
    "an",
    "is",
    "it",
    "for",
    "on",
    "with",
    "as",
    "by",
    "at",
    "from",
    "that",
    "this",
    "be",
    "are",
    "was",
    "were",
    "has",
    "have",
    "had",
}


def remove_refs(text):
    """
    Remove quotations like "[23]" from the text.
    """
    result = ""
    inside_brackets = False

    for char in text:
        if char == "[":
            inside_brackets = True
        elif char == "]":
            inside_brackets = False
        elif not inside_brackets:
            result += char

    return result


def process(text):
    """
    Turn the entire text into lower case, remove punctuation, citation brackets, extra spaces.
    """
    text = text.lower()
    text = remove_refs(text)
    text = text.translate(PUNCT_TABLE)

    while "  " in text:
        text = text.replace("  ", " ")

    return text.strip()


def tokenize(text):
    tokens = []
    words = text.split(" ")

    for w in words:
        if w == "":
            continue
        if w in STOP_WORDS:
            continue
        tokens.append(w)

    return tokens


def split_sentences(text):
    """Splits sentences using '.', '!' and '?' as boundaries."""
    boundary = text.replace("!", ".").replace("?", ".")
    sentences = boundary.split(".")
    return [s for s in sentences if s != ""]


# ---------------------------------------------------------------
# 3. ---------  Copy from Wikipedia & Build Database  -----------
# ---------------------------------------------------------------
""" Copied from mediawiki: https://github.com/barrust/mediawiki """
def copy_article(title):
    return WIKI.page(title).content


def build_database():
    titles = {}
    raw_texts = {}
    for title in ALL_TITLES:
        raw = copy_article(title)
        raw_texts[title] = raw
        clean = process(raw)
        tokens = tokenize(clean)
        titles[title] = set(tokens)
    return titles, raw_texts


# ---------------------------------------------------------------
# 4. -------------------  Statistics  ---------------------------
# ---------------------------------------------------------------
def stats(tokens, raw_text):
    sentences = split_sentences(raw_text)
    total_words = len(tokens)

    if total_words == 0:
        avg_word_len = 0
    else:
        total_length = 0
        for word in tokens:
            total_length += len(word)
        avg_word_len = total_length / total_words

    if len(sentences) == 0:
        avg_sentence_len = 0
    else:
        total_sentence_words = 0
        for sentence in sentences:
            words_in_sentence = sentence.split()
            total_sentence_words += len(words_in_sentence)
        avg_sentence_len = total_sentence_words / len(sentences)

    return total_words, avg_word_len, avg_sentence_len


# ---------------------------------------------------------------
# 5. ----------------------  JACCARD  ---------------------------
# ---------------------------------------------------------------
""" The use of JACCARD was brought up by ChatGPT during my initial brainstorming stage,
    I liked the idea and decided to expand on it. This part is generated by ChatGPT. """
def jaccard(set_a, set_b):
    return len(set_a & set_b) / len(set_a | set_b) if set_a or set_b else 0.0


# ---------------------------------------------------------------
# 6. ------------------------  Report  --------------------------
# ---------------------------------------------------------------
def main():
    """I used ChatGPT to help me on formatting of the report after running the codes."""
    titles, raw_texts = build_database()

    print("\n\n\nReport on Articles")
    print("-" * 85)
    print(f"{'Article Name':38} {'Words':>8} {'AvgWordLen':>12} {'AvgSentenceLen':>16}")
    print("-" * 85)
    for title in ALL_TITLES:
        tokens = tokenize(process(raw_texts[title]))
        w, aw, aslen = stats(tokens, raw_texts[title])
        print(f"{title[:38]:38} {w:8d} {aw:12.2f} {aslen:16.2f}")
    print("-" * 85)

    print("\n\n\nVocabulary JACCARD Similarity Score (Schools vs. References)")
    print("-" * 85)
    print(f"{'School':35}  Entrepreneurship  U.S.News")
    print("-" * 85)
    eps_set = titles["Entrepreneurship"]
    usn_set = titles["U.S. News & World Report"]

    for school in SCHOOLS:
        j_ent = jaccard(titles[school], eps_set)
        j_usn = jaccard(titles[school], usn_set)
        print(f"{school[:35]:35}      {j_ent:.3f}            {j_usn:.3f}")
    print("-" * 85)


if __name__ == "__main__":
    main()
